The COVID-19 pandemic has created an enormous amount of data that needs to be managed and analyzed to help understand the spread and impact of the disease. In order to manage this data, we are using AWS cloud services to store and process the data. To store the data, we are using an AWS S3 bucket, which allows us to store and access large amounts of data from anywhere. To extract and transform the data, we are using AWS Glue, a powerful ETL (Extract, Transform, Load) service that allows us to write code to transform and manipulate the data as needed. We also use Amazon crawler to automate the extraction of data from the S3 bucket and create data catalog tables. To query and analyze the data, we use AWS Athena, a serverless query service that allows us to analyze data directly in S3 without the need for complex ETL processes.
Our data includes Covid-19 related information such as country-wise and state-wise data, hospital beds, vaccination counts, demographic information, and more. To make the data easier to understand and analyze, we transformed it from a relational data model into a star schema data model. In a star schema, data is organized into dimension tables and a fact table, which allows us to easily analyze and understand the data. We created three dimension tables and one fact table to represent the Covid-19 data.
Finally, we created a data warehouse on AWS Redshift, which is a fully managed, petabyte-scale data warehouse service in the cloud. By connecting Redshift to visualization tools such as Tableau or Power BI, users can create interactive dashboards and visualizations to better understand and communicate the insights gained from the data.